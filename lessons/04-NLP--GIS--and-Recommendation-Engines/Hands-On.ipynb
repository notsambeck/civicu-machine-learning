{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on NLP and Naive Bayes\n",
    "\n",
    "Prepared by Chris Gian for Hack Oregon's Week \n",
    "Sources:\n",
    "- Based mostly on: [Lab 10 of Harvard's CS109](https://github.com/cs109/2015lab10) class. \n",
    "- Adapted for use with sklearn way of text processing: [Working With Text Data](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n",
    "- Hobson Lane's book: [NLP in Action](https://www.manning.com/books/natural-language-processing-in-action)\n",
    "\n",
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm  # you have to download this\n",
    "nlp = en_core_web_sm.load() \n",
    "data_spacy = df\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "\n",
    "# Vectorize, Transform\n",
    "def make_X(data, min_df_in, stopwords, lowercase, ngram):\n",
    "    vectorizer = CountVectorizer(min_df=min_df_in, stop_words=stopwords, \n",
    "                                 lowercase=lowercase, ngram_range=ngram)\n",
    "    term_doc_matrix = vectorizer.fit_transform(data)\n",
    "    term_doc_matrix = term_doc_matrix.todense()\n",
    "    term_doc_matrix = pd.DataFrame(term_doc_matrix)\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(term_doc_matrix)\n",
    "    tfidf = pd.DataFrame(tfidf.toarray())\n",
    "    return tfidf, vectorizer, transformer\n",
    "\n",
    "# Send scores to a google docs\n",
    "def post_score(name, your_score):\n",
    "    send = 'https://docs.google.com/forms/d/e/1FAIpQLSfOdYRNhf_z3PsHDxMu-IoqaUbUaI9uSHflExgZuBoC1HNvtQ/formResponse?'    \n",
    "    send += 'entry.278237990=' + name\n",
    "    send += '&entry.415269798=' + str(your_score)\n",
    "    r = requests.post(send)\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data + Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "critics = pd.read_csv('resources/critics.csv')\n",
    "critics = critics[critics.fresh != 'none']\n",
    "df = critics.copy().dropna()\n",
    "# split\n",
    "X = df.quote\n",
    "y = df.fresh == 'fresh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1     2     3     4     5     6     7     8     9     ...   2942  \\\n",
      "1952    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "3646    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "4174    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "3659    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "13989   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "\n",
      "       2943      2944      2945  2946  2947  2948  2949  2950  2951  \n",
      "1952    0.0  0.000000  0.423208   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3646    0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4174    0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3659    0.0  0.326241  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "13989   0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 2952 columns]\n"
     ]
    }
   ],
   "source": [
    "x_in = X # YOUR TURN:  <--- Your engineered features go here.\n",
    "\n",
    "X2, vectorizer_2, transformer_2 = make_X(\n",
    "    x_in,\n",
    "    min_df_in= 10, # Option.\n",
    "    stopwords = stopwords,\n",
    "    lowercase = True, # Option.\n",
    "    ngram = (1,1) # Option.\n",
    ")\n",
    "\n",
    "\n",
    "# Create Hold data set to judge predictive ability on new data\n",
    "seed = 100\n",
    "X_train, X_test,y_train, y_test = train_test_split(X2,y, test_size=0.15, random_state=seed)\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your classifier\n",
    "- Try other classifiers as well\n",
    "\n",
    "If you're using Naive Bayes. There's a single tuning parameter:\n",
    "\n",
    "**Alpha:** [From Wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    "\n",
    "\"If a given class and feature value never occur together in the training data, then the frequency-based probability estimate will be zero. This is problematic because it will wipe out all information in the other probabilities when they are multiplied. Therefore, it is often desirable to incorporate a small-sample correction, called pseudocount, in all probability estimates such that no probability is ever set to be exactly zero. This way of regularizing naive Bayes is called Laplace smoothing when the pseudocount is one, and Lidstone smoothing in the general case.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = MultinomialNB(alpha=.1)  # A smoothing parameter. \n",
    "clf = SVC(kernel='sigmoid')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = clf.score(X_test,y_test)\n",
    "print(\"Accuracy on Test Data: %f\" % a\n",
    "# print(\"Accuracy on Test Data: %f\" % clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24548736,  0.14891697],\n",
       "       [ 0.08122744,  0.52436823]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_pred= y_pred, y_true=y_test)\n",
    "cm / cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.62      0.68       874\n",
      "       True       0.78      0.87      0.82      1342\n",
      "\n",
      "avg / total       0.77      0.77      0.77      2216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred = y_pred, y_true = y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post your score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam, Accuracy score of: 0.769856\n"
     ]
    }
   ],
   "source": [
    "name = \"Sam\"\n",
    "result = clf.score(X_test,y_test)\n",
    "print('%s, Accuracy score of: %f' % (name, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "post_score(name = name, your_score = np.round(result,decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.5.2"
=======
   "version": "3.5.3"
>>>>>>> 8aea3aff4afd44bce8482ce5cc7863f838b12e59
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
